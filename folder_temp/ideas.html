<html>
<head>
<link rel="stylesheet" href="stylesheet.css">
</head>
<body>
<ul>
<li>So to speak, math is the set of things that are true even if you desperately want them to be false. But why would you desperately want everything in the world to be false? In fact, placebo is warm and fuzzy because it works when you want it to work. It affirms the power of the will. 
<li>I bristle at the answer ``it depends" because obviously, it depends. Everything will always depend on everything else. It is like saying "I breathe" before starting the answer. 
<li>
<img src="annoying.jpg"/>
I find these arguments extremely annoying because it is emblematic of the pretension of researchers to assume certain absurd assumptions and do not have any consciousness of those assumptions. It divorces context from reasoning, unknowingly stepping into the context of white space, and declares that the reasoning conducted in the white space is the only true reasoning and the poor stupid laymen are wrong because they reason according to, as any *rational* person would do, a familiar context. 
<br>
What is a familiar context for choosing someone at random? Walking down the street and talking to someone, perhaps. To do this one must first be in a location. To get to a location one must have a destination. So let's back up a little bit. To choose a person at random, we first choose a destination at random. Destination, not location, mind you. Then we choose a person at random from that destination. 
<br>
What destinations are there? Mostly cities.  Because of this fact, the conveniently context-divorced fact that there are twenty times as many farmers as librarians holds not much weight. 
<br>
 The fact that Steve was "chosen at random", a patently absurd notion, is given as an assumption one can just *make*. How can anyone do that? To choose someone at random, one must have a context.  
<li> But laughter has limited functionality. Suppose I ask my mother one day that I want to get Spotify premium, and she replies, but why? We have the radio. Upon my explanation that on Spotify premium, I can choose what song I want to listen to, my mom laughs, turns to my dad, and repeats what I said, expecting a laughter. <br>

Here, the function of the laughter is at once to suppress comprehension of the novel point of view - that one may want to be able to *choose* what song to listen to - and at second to seek confirmation that this suppression was the right choice to make. In this way, laughter prohibits novel ideas from gaining traction. 

<li> H is in a culture that constantly humiliates H if and only if H is in a culture that contradicts his own. 

<li> Usually, "everything is A" is a vacuous statement, because that everything is A means nothing is not A and what we are really interested in is what makes something A and what makes something not A. The situation is different with "everything is computation". With this statement, we give ourselves license to the wholesale import of powerful results in computational complexity theory. 

<li> Too often, freedom is confused with taking away others' freedom. 

<li> Money lets you compute others. <br>
Sweetness: industrial grade lies. Very computable. 

<li> In Korea, the very notion of the absurd is absurd because everyone has a clear role to play. There are clear things others expect one to do, and visceral consequences upon failure. 
<br>
To talk of philosophy without first talking of culture is at best blind ignorance and at worst belief in racial superiority. To talk about ethics, knowledge, metaphysics, and language without consulting and cross-checking those of other cultures is to hold haughty contempt towards entire oceans of human wisdom distilled over millenia because of the color of its skin. 

<li> "how can we get a cognitive science that allows us to talk about units of mind that are neither wholly internal nor external - perched on the mind-world line - yet compatible with the mind as an acontextual device and contextual agent? The answer can he found in the ways both computational theory and sociocultural theory use certain parts of language to manage the trade-off between internal mental architecture and the external context in which the architecture operates." <i>Vygotsky and Cognitive Science</i>

<li> "Never tackle a problem of which you can be pretty sure that (now or in the near future) it will be tackled by others who are, in relation to that problem, at least as competent and well-equipped as you." --Dijkstra

<li> That isn't vs that's not

<li> Change is unpredictable. The only unpredictable thing is a human. Change comes from the body. Verbs come from the body. <br>

What is predictable is what does not change. Nouns are predictable. Nouns come from outside of a human. Nouns come from objects. <br>

"objective" - how do objects have a point of view? But they do. Objects have a point of view. Objects have a point of view, a clear, unmuddled perspective of the world. 

<li> Infinity is the fact that you have to do *something*, that because others are waiting. You need to act in some way. You can't keep reprocessing. You can't keep thinking indefinitely. You need to do somerhibg

<li> By walking orthogonally, you are least likely to get in somebody's way. 

<li> What is cliché, what doesn't even count as a metaphor, in one language is poetic in another. 

<li> What is embarrassing about ordering something wrong? It is that you break out of the frame and must interact with each other as human beings; your act has suddenly ended. 

<li> A kid stays singing at a mall and all the adults, instead of laughing at him, start singing along, until everyone is singing and nobody is buying anything.

<li> Byes and his are important in a culture where you must continually keep in mind whether a person is around you or not. 
<br>
To say bye is to allow the other person to pop off his stack of you. If this stack is left unresolved there is anxiety. 

<li> It is precisely our failure to compress the information of cats that give them their value.

<li> Imagine a world with no people, no animals, no plants.

Nothing moves save for wind. Wind is predictable, conveniently.

The world tends toward more and more unpredictability.

It is our fate to make the world more unpredictable.

But why go for a world where everything is random?

Random in what sense? In the sense that we cannot understand it.

<li>
I used to be part of the 99%. I was very bad at math. I feared math, despised its disciples, and would rather have lived in a world without it. That is, until I took a linguistics class. 
<br>
Well, it wasn't just *a* linguistics class. It was a linguistics class taught by no less a man than George Lakoff, the founder of Conceptual Metaphor Theory, which is one of the most ambitious and influential Theories of Everything. 
<br>
The basis of CMT is as simple as it is profound. CMT posits that all of human cognition emerges from the intertwining and stacking of a handful of what are called "primitive metaphors". Think of the alphabet: the whole of it is composed of vertical lines, horizontal lines, circles and half-circles. These "primitive patterns", if you will, distort and combine in interesting ways to form all of the alphabet. So, too, Lakoff and his disciples claim, does human cognition. 
<br>
Of course, math is a subset of human cognition, and must play by these rules. In his book _Where Mathematics Comes From_, Lakoff provides a fascinating decomposition of math into primitive metaphors, culminating in a Proof by Metaphor (specifically, motor control) of the most celebrated equation of the 18th century, e^pi*i = -1. After reading Lakoff's explanation, one gets the sense that nothing is really imaginary about i and how better the world would have been if it hadn't been christened by such a frightening and, frankly, immoral, name. 
<br>
The main victory is that math, though often revered and feared like a satanic cult, is nothing more than the repeated application of concepts that *everyone* - *everyone* - possesses. Think of the Peano axioms. The only profound idea in those axioms is that there is such a thing as an origin, or zero, and that there is such a concept as being bigger. For the ZF axioms, just add the metaphor of in-ness. And voilá, all of math.
<br>
Unfortunately, this isn't a popular view of math. Call me cynical, but I suspect the reason is the product of a divine snobbery among mathematicians that is no different from the ancient snobbery of shamans. Mathematics enjoys immense prestige, which is another way of saying that only a select few people know it. One wonders why this is the case. Then one remembers how it is taught, and stops wondering.
<br>
The main problem of mathematics education is that it presumes a Platonic view of math. In other words, it is no different from religion. Students are expected to, literally, "take on faith" that a certain theorem "just works". At least religion rewards you with a community and bread and wine for holding baseless convictions. Not so in math, so why would anyone bother?
<br>
Of course, some *do* bother. In the words of Jonathan Shewchuk, a professor of computer science at Cal, these are "the elite brilliant few who have painstakingly decoded the mumblings of their forebears." I like this sentence, but would like it more after redefining "elite brilliant": those people who happen to be good at making metaphor from symbols on paper to the primitive concepts beneath. A decomposition of the theorem into primitive metaphors should be the norm.

<li> There is a persistent confusion between the computable and the uncomputable. There is a persistent confusion on whether if something is known, whether it can be free, in other words, whether knowledge of an object and the object’s free will are two mutually irreconcilable things. Reductionism, with its poor philosophical foundation usually based on a shaky understanding of the ego and of running from the ego through fancy mathematical proofs and notations that establish one’s sovereignty and dominance over others, that “philosophy”, is at the forefront of this effort wielding pitchforks.  

<li> (literal) negative bias: do people think of negative numbers as bigger in magnitude than positive numbers?

<li> The fundamental misconception of language is that language is used for communication.
<br>
Language is not used for communication. It is used to elicit what is already there. Almost always, the sound is used to elicit what is already there.

<li> Something is true if it has changed you in an irrevocable way. The trauma of Wes telling me I'm just not that smart is true because it changed be in an irrevocable way. People cannot "just see the truth". To see a truth disparate form their own truths is to rip away their past selves. Of course, if there is more to be gained from the new truth, it will do them good to switch, for clinging to the old truth only extends their self that is built on doubt. If there is a doubt of old truth it is cowardly not to reject it.  

<li> When people who don't know you talk behind your back, they are literally not talking about you. They are talking about the people that you map to in their minds. Now it is despairing if you think, in their minds, you *are* that person. But it is not true; they are literally not talking about you, they are talking about another person who has disappointed them profoundly, and they seem to be talking about you only because of a thin connection somehow set up between you and that person. The despair is there because of the profound sadness, because you do not think you can rid these people of this profound sadness, but fortunately you are not the object of the profound sadness, only a very convenient and mostly meaningless scapegoat. 

</ul>
<a href="index.html">Back</a>
</body>
